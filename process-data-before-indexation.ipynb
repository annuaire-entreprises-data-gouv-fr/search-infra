{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import swifter\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DIR\" not in locals():\n",
    "    DATA_DIR = \"./data/\"\n",
    "else:\n",
    "    print(DATA_DIR)\n",
    "\n",
    "if os.path.exists(DATA_DIR) and os.path.isdir(DATA_DIR):\n",
    "    shutil.rmtree(DATA_DIR)\n",
    "os.makedirs(os.path.dirname(DATA_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"OUTPUT_DATA_FOLDER\" not in locals():\n",
    "    OUTPUT_DATA_FOLDER = \"./output/\"\n",
    "else:\n",
    "    print(OUTPUT_DATA_FOLDER)\n",
    "\n",
    "if os.path.exists(OUTPUT_DATA_FOLDER) and os.path.isdir(OUTPUT_DATA_FOLDER):\n",
    "    shutil.rmtree(OUTPUT_DATA_FOLDER)\n",
    "os.makedirs(os.path.dirname(OUTPUT_DATA_FOLDER), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"LABELS_FOLDER\" not in locals():\n",
    "    LABELS_FOLDER = \"./labels/\"\n",
    "else:\n",
    "    print(LABELS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ELASTIC_INDEX\" not in locals():\n",
    "    ELASTIC_INDEX = \"siren\"\n",
    "else:\n",
    "    print(ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Établissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of departement zip codes\n",
    "all_deps = [\n",
    "    *\"-0\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "    *list(str(x) for x in range(10, 20)),\n",
    "    *[\"2A\", \"2B\"],\n",
    "    *list(str(x) for x in range(21, 96)),\n",
    "    *\"-7510\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "    *\"-751\".join(list(str(x) for x in range(10, 21))).split(\"-\")[1:],\n",
    "    *[\"971\", \"972\", \"973\", \"974\", \"976\"],\n",
    "    *[\"\"],\n",
    "]\n",
    "# Remove Paris zip code\n",
    "all_deps.remove(\"75\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deps = [\"23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Upload geo data by departement\n",
    "for dep in all_deps:\n",
    "    url = \"https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_\" + dep + \".csv.gz\"\n",
    "    print(url)\n",
    "    df_dep = pd.read_csv(\n",
    "        url,\n",
    "        compression=\"gzip\",\n",
    "        dtype=str,\n",
    "        usecols=[\n",
    "            \"siren\",\n",
    "            \"siret\",\n",
    "            \"dateCreationEtablissement\",\n",
    "            \"trancheEffectifsEtablissement\",\n",
    "            \"activitePrincipaleRegistreMetiersEtablissement\",\n",
    "            \"etablissementSiege\",\n",
    "            \"numeroVoieEtablissement\",\n",
    "            \"libelleVoieEtablissement\",\n",
    "            \"codePostalEtablissement\",\n",
    "            \"libelleCommuneEtablissement\",\n",
    "            \"libelleCedexEtablissement\",\n",
    "            \"typeVoieEtablissement\",\n",
    "            \"codeCommuneEtablissement\",\n",
    "            \"codeCedexEtablissement\",\n",
    "            \"complementAdresseEtablissement\",\n",
    "            \"distributionSpecialeEtablissement\",\n",
    "            'complementAdresse2Etablissement',\n",
    "            \"dateDebut\",\n",
    "            \"etatAdministratifEtablissement\",\n",
    "            \"enseigne1Etablissement\",\n",
    "            \"enseigne1Etablissement\",\n",
    "            \"enseigne2Etablissement\",\n",
    "            \"enseigne3Etablissement\",\n",
    "            \"denominationUsuelleEtablissement\",\n",
    "            \"activitePrincipaleEtablissement\",\n",
    "            \"geo_adresse\",\n",
    "            \"geo_id\",\n",
    "            \"longitude\",\n",
    "            \"latitude\",\n",
    "            \"indiceRepetitionEtablissement\",\n",
    "        ],\n",
    "    )\n",
    "    df_dep = df_dep.rename(\n",
    "        columns={\n",
    "            \"dateCreationEtablissement\": \"date_creation\",\n",
    "            \"trancheEffectifsEtablissement\": \"tranche_effectif_salarie\",\n",
    "            \"activitePrincipaleRegistreMetiersEtablissement\": \"activite_principale_registre_metier\",\n",
    "            \"etablissementSiege\": \"is_siege\",\n",
    "            \"numeroVoieEtablissement\": \"numero_voie\",\n",
    "            \"typeVoieEtablissement\": \"type_voie\",\n",
    "            \"libelleVoieEtablissement\": \"libelle_voie\",\n",
    "            \"codePostalEtablissement\": \"code_postal\",\n",
    "            \"libelleCedexEtablissement\": \"libelle_cedex\",\n",
    "            \"libelleCommuneEtablissement\": \"libelle_commune\",\n",
    "            \"codeCommuneEtablissement\": \"commune\",\n",
    "            \"complementAdresseEtablissement\": \"complement_adresse\",\n",
    "            \"complementAdresse2Etablissement\": \"complement_adresse_2\",\n",
    "            \"numeroVoie2Etablissement\": \"numero_voie_2\",\n",
    "            \"indiceRepetition2Etablissement\": \"indice_repetition_2\",\n",
    "            \"typeVoie2Etablissement\": \"type_voie_2\",\n",
    "            \"libelleVoie2Etablissement\": \"libelle_voie_2\",\n",
    "            \"codePostal2Etablissement\": \"code_postal_2\",\n",
    "            \"codeCedexEtablissement\": \"cedex\",\n",
    "            \"dateDebut\": \"date_debut_activite\",\n",
    "            \"distributionSpecialeEtablissement\": \"distribution_speciale\",\n",
    "            \"etatAdministratifEtablissement\": \"etat_administratif_etablissement\",\n",
    "            \"enseigne1Etablissement\": \"enseigne_1\",\n",
    "            \"enseigne2Etablissement\": \"enseigne_2\",\n",
    "            \"enseigne3Etablissement\": \"enseigne_3\",\n",
    "            \"activitePrincipaleEtablissement\": \"activite_principale\",\n",
    "            \"indiceRepetitionEtablissement\": \"indice_repetition\",\n",
    "            \"denominationUsuelleEtablissement\": \"nom_commercial\",\n",
    "        }\n",
    "    )\n",
    "    df_dep.to_csv(DATA_DIR + \"geo_siret_\" + dep + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geo data file paths\n",
    "geo_files = glob.glob(DATA_DIR + \"geo_siret*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute nbre d'établissements' per 'siren'\n",
    "df_out = pd.DataFrame()\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file, dtype=str)\n",
    "    df_geo = df_geo.replace({np.nan: None})\n",
    "    df_geo[\"file\"] = geo_file\n",
    "    # Create column with list of \"enseignes\" and \"nom_commercial\"\n",
    "    df_geo[\"enseigne\"] = df_geo.apply(\n",
    "        lambda x: list(\n",
    "            filter(\n",
    "                None,\n",
    "                set(\n",
    "                    [\n",
    "                        x[\"enseigne_1\"],\n",
    "                        x[\"enseigne_2\"],\n",
    "                        x[\"enseigne_3\"],\n",
    "                        x[\"nom_commercial\"],\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    df_geo[\"nombre_etablissements\"] = df_geo.groupby([\"siren\", \"file\"])[\n",
    "        \"siret\"\n",
    "    ].transform(\"count\")\n",
    "    df_enseigne = (\n",
    "        df_geo.groupby([\"siren\", \"file\"])[\"enseigne\"]\n",
    "        .apply(list)\n",
    "        .reset_index(name=\"liste_enseigne_dep\")\n",
    "        .drop(columns=[\"file\"], axis=1)\n",
    "    )\n",
    "    df_enseigne[\"liste_enseigne_dep\"] = df_enseigne.apply(\n",
    "        lambda x: list(set(c for b in x.liste_enseigne_dep for c in b)), axis=1\n",
    "    )\n",
    "    df_geo = df_geo.merge(df_enseigne, left_on=\"siren\", right_on=\"siren\")\n",
    "    df_adresse = (\n",
    "        df_geo.groupby([\"siren\", \"file\"])[\"geo_adresse\"]\n",
    "        .apply(set)\n",
    "        .reset_index(name=\"liste_adresse_dep\")\n",
    "        .drop(columns=[\"file\"], axis=1)\n",
    "    )\n",
    "    df_geo = df_geo.merge(df_adresse, left_on=\"siren\", right_on=\"siren\")\n",
    "    df_inter = df_geo[\n",
    "        [\n",
    "            \"siren\",\n",
    "            \"file\",\n",
    "            \"nombre_etablissements\",\n",
    "            \"liste_enseigne_dep\",\n",
    "            \"liste_adresse_dep\",\n",
    "        ]\n",
    "    ]\n",
    "    df_out = pd.concat([df_out, df_inter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_out = df_out.drop_duplicates(subset=[\"siren\", \"file\"], keep=\"first\")\n",
    "df_liste = (\n",
    "    df_out.groupby([\"siren\"])[\"liste_enseigne_dep\"]\n",
    "    .apply(list)\n",
    "    .reset_index(name=\"liste_enseigne\")\n",
    ")\n",
    "df_out = df_out.merge(df_liste, left_on=\"siren\", right_on=\"siren\")\n",
    "df_liste = (\n",
    "    df_out.groupby([\"siren\"])[\"liste_adresse_dep\"]\n",
    "    .apply(list)\n",
    "    .reset_index(name=\"liste_adresse\")\n",
    ")\n",
    "df_out = df_out.merge(df_liste, left_on=\"siren\", right_on=\"siren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out2 = (\n",
    "    df_out[[\"siren\", \"nombre_etablissements\"]].groupby([\"siren\"], as_index=False).sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out2 = df_out2.merge(\n",
    "    df_out[[\"liste_enseigne\", \"liste_adresse\", \"siren\"]], on=\"siren\", how=\"left\"\n",
    ")\n",
    "df_out2 = df_out2.drop_duplicates(subset=[\"siren\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out2[\"liste_enseigne\"] = df_out2.apply(\n",
    "    lambda x: list(set(c for b in x.liste_enseigne for c in b)), axis=1\n",
    ")\n",
    "df_out2[\"liste_adresse\"] = df_out2.apply(\n",
    "    lambda x: list(set(c for b in x.liste_adresse for c in b)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unité Légale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Import Stock Unite Legale data\n",
    "df_unite_legale = pd.read_csv(\n",
    "    \"https://files.data.gouv.fr/insee-sirene/StockUniteLegale_utf8.zip\",\n",
    "    compression=\"zip\",\n",
    "    dtype=str,\n",
    "    usecols=[\n",
    "        \"siren\",\n",
    "        \"dateCreationUniteLegale\",\n",
    "        \"sigleUniteLegale\",\n",
    "        \"prenom1UniteLegale\",\n",
    "        \"identifiantAssociationUniteLegale\",\n",
    "        \"trancheEffectifsUniteLegale\",\n",
    "        \"dateDernierTraitementUniteLegale\",\n",
    "        \"categorieEntreprise\",\n",
    "        \"etatAdministratifUniteLegale\",\n",
    "        \"nomUniteLegale\",\n",
    "        \"nomUsageUniteLegale\",\n",
    "        \"denominationUniteLegale\",\n",
    "        \"categorieJuridiqueUniteLegale\",\n",
    "        \"activitePrincipaleUniteLegale\",\n",
    "        \"economieSocialeSolidaireUniteLegale\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Rename columns\n",
    "df_unite_legale = df_unite_legale.rename(\n",
    "    columns={\n",
    "        \"dateCreationUniteLegale\": \"date_creation_unite_legale\",\n",
    "        \"sigleUniteLegale\": \"sigle\",\n",
    "        \"prenom1UniteLegale\": \"prenom\",\n",
    "        \"trancheEffectifsUniteLegale\": \"tranche_effectif_salarie_unite_legale\",\n",
    "        \"dateDernierTraitementUniteLegale\": \"date_mise_a_jour_unite_legale\",\n",
    "        \"categorieEntreprise\": \"categorie_entreprise\",\n",
    "        \"etatAdministratifUniteLegale\":\"etat_administratif_unite_legale\",\n",
    "        \"nomUniteLegale\": \"nom\",\n",
    "        \"nomUsageUniteLegale\": \"nom_usage\",\n",
    "        \"denominationUniteLegale\": \"nom_raison_sociale\",\n",
    "        \"categorieJuridiqueUniteLegale\": \"nature_juridique_unite_legale\",\n",
    "        \"activitePrincipaleUniteLegale\": \"activite_principale_unite_legale\",\n",
    "        \"economieSocialeSolidaireUniteLegale\":\"economie_sociale_solidaire_unite_legale\",\n",
    "        \"identifiantAssociationUniteLegale\":\"identifiant_association_unite_legale\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nom_complet(x):\n",
    "    if x[\"nature_juridique_unite_legale\"] == \"1000\":\n",
    "        if x[\"sigle\"] == x[\"sigle\"]:\n",
    "            if (x[\"prenom\"] == x[\"prenom\"]) & (x[\"nom\"] == x[\"nom\"]):\n",
    "                if x[\"nom usage\"] == x[\"nom_usage\"]:\n",
    "                    return (\n",
    "                        x[\"prenom\"].lower()\n",
    "                        + \" \"\n",
    "                        + x[\"nom_usage\"].lower()\n",
    "                        + \" (\"\n",
    "                        + x[\"nom\"].lower()\n",
    "                        + \", \"\n",
    "                        + x[\"sigle\"].lower()\n",
    "                        + \")\"\n",
    "                    )\n",
    "                else:\n",
    "                    return (\n",
    "                        x[\"prenom\"].lower()\n",
    "                        + \" \"\n",
    "                        + x[\"nom\"].lower()\n",
    "                        + \" (\"\n",
    "                        + x[\"sigle\"].lower()\n",
    "                        + \")\"\n",
    "                    )\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            if (x[\"prenom\"] == x[\"prenom\"]) & (x[\"nom\"] == x[\"nom\"]):\n",
    "                if x[\"nom_usage\"] == x[\"nom_usage\"]:\n",
    "                    return (\n",
    "                        x[\"prenom\"].lower()\n",
    "                        + \" \"\n",
    "                        + x[\"nom_usage\"].lower()\n",
    "                        + \" (\"\n",
    "                        + x[\"nom\"].lower()\n",
    "                        + \")\"\n",
    "                    )\n",
    "                else:\n",
    "                    return x[\"prenom\"].lower() + \" \" + x[\"nom\"].lower()\n",
    "            else:\n",
    "                return None\n",
    "    else:\n",
    "        if x[\"sigle\"] == x[\"sigle\"]:\n",
    "            if x[\"nom_raison_sociale\"] == x[\"nom_raison_sociale\"]:\n",
    "                return x[\"nom_raison_sociale\"].lower() + \" (\" + x[\"sigle\"].lower() + \")\"\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            if x[\"nom_raison_sociale\"] == x[\"nom_raison_sociale\"]:\n",
    "                return x[\"nom_raison_sociale\"].lower()\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Add nom_complet column to df_unite_legale\n",
    "# swifter.allow_dask_on_strings()\n",
    "df_unite_legale[\"nom_complet\"] = df_unite_legale.apply(\n",
    "    lambda row: nom_complet(row), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge unité légale et établissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unite_legale = pd.merge(df_unite_legale, df_out2, on=\"siren\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unite_legale.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections Codes NAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name: str):\n",
    "    with open(file_name) as json_file:\n",
    "        file_decoded = json.load(json_file)\n",
    "    return file_decoded\n",
    "# sections_NAF = load_file(f\"{LABELS_FOLDER}sections_codes_naf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sections_NAF = {\n",
    "\"01\":\"A\",\"02\":\"A\",\"03\":\"A\",\"05\":\"B\",\"06\":\"B\",\"07\":\"B\",\"08\":\"B\",\"09\":\"B\",\"10\":\"C\",\"11\":\"C\",\"12\":\"C\",\"13\":\"C\",\"14\":\"C\",\n",
    " \"15\":\"C\",\"16\":\"C\",\"17\":\"C\",\"18\":\"C\",\"19\":\"C\",\"20\":\"C\",\"21\":\"C\",\"22\":\"C\",\"23\":\"C\",\"24\":\"C\",\"25\":\"C\",\"26\":\"C\",\"27\":\"C\",\n",
    " \"28\":\"C\",\"29\":\"C\",\"30\":\"C\",\"31\":\"C\",\"32\":\"C\",\"33\":\"C\",\"35\":\"D\",\"36\":\"E\",\"37\":\"E\",\"38\":\"E\",\"39\":\"E\",\"41\":\"F\",\"42\":\"F\",\n",
    " \"43\":\"F\",\"45\":\"G\",\"46\":\"G\",\"47\":\"G\",\"49\":\"H\",\"50\":\"H\",\"51\":\"H\",\"52\":\"H\",\"53\":\"H\",\"55\":\"I\",\"56\":\"I\",\"58\":\"J\",\"59\":\"J\",\n",
    " \"60\":\"J\",\"61\":\"J\",\"62\":\"J\",\"63\":\"J\",\"64\":\"K\",\"65\":\"K\",\"66\":\"K\",\"68\":\"L\",\"69\":\"M\",\"70\":\"M\",\"71\":\"M\",\"72\":\"M\",\"73\":\"M\",\n",
    " \"74\":\"M\",\"75\":\"M\",\"77\":\"N\",\"78\":\"N\",\"79\":\"N\",\"80\":\"N\",\"81\":\"N\",\"82\":\"N\",\"84\":\"O\",\"85\":\"P\",\"86\":\"Q\",\"87\":\"Q\",\"88\":\"Q\",\n",
    " \"90\":\"R\",\"91\":\"R\",\"92\":\"R\",\"93\":\"R\",\"94\":\"S\",\"95\":\"S\",\"96\":\"S\",\"97\":\"T\",\"98\":\"T\",\"99\":\"U\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nombre établissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 'nombre etablissements ouverts' per 'siren'\n",
    "df_out = pd.DataFrame()\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file, dtype=str)\n",
    "    df_geo = df_geo[df_geo[\"etat_administratif_etablissement\"] == \"A\"]\n",
    "    df_geo[\"file\"] = geo_file\n",
    "    df_geo[\"nombre_etablissements_ouverts\"] = df_geo.groupby([\"siren\", \"file\"])[\n",
    "        \"siret\"\n",
    "    ].transform(\"count\")\n",
    "    df_inter = df_geo[[\"siren\", \"file\", \"nombre_etablissements_ouverts\"]]\n",
    "    df_out = pd.concat([df_out, df_inter])\n",
    "df_out = df_out.drop_duplicates(keep=\"first\")\n",
    "df_out2 = (\n",
    "    df_out[[\"siren\", \"nombre_etablissements_ouverts\"]]\n",
    "    .groupby([\"siren\"], as_index=False)\n",
    "    .sum()\n",
    ")\n",
    "df_unite_legale = pd.merge(df_unite_legale, df_out2, on=\"siren\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unite_legale[\"section_activite_principale\"] = df_unite_legale['activite_principale_unite_legale'].str[:2].map(sections_NAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adresse_complete(row):\n",
    "    col_list = [\"complement_adresse\", \"numero_voie\", \"indice_repetition\", \"type_voie\", \"libelle_voie\", \"distribution_speciale\"]\n",
    "    adresse = \"\"\n",
    "    for column in col_list:\n",
    "        adresse = adresse + (\" \" + str(row[column]) if row[column] else \"\")\n",
    "    if row[\"cedex\"] is None:\n",
    "        return adresse + \" \" + str(row[\"commune\"]) + \" \" + str(row[\"libelle_commune\"]) \n",
    "    return adresse + \" \" + str(row[\"cedex\"]) + \" \" + str(row[\"libelle_cedex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geo files with above dataframe and add is_entrepreneur_individuel\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file, dtype=str)\n",
    "    df_inter = pd.merge(df_geo, df_unite_legale, on=\"siren\", how=\"left\")\n",
    "    df_inter2 = df_inter[df_inter[\"is_siege\"] == \"true\"]\n",
    "    df_inter2[\"concat_nom_adr_siren\"] = (\n",
    "        df_inter2[\"nom_complet\"]\n",
    "        + \" \"\n",
    "        + df_inter2[\"geo_adresse\"]\n",
    "        + \" \"\n",
    "        + df_inter2[\"siren\"]\n",
    "    )\n",
    "   \n",
    "    # df_inter2['concat_enseigne_adresse'] = df_inter2.apply(lambda x: set.union(x.liste_enseigne, x.liste_adresse), axis=1)\n",
    "    df_inter2[\"concat_enseigne_adresse\"] = (\n",
    "        df_inter2[\"liste_enseigne\"] + df_inter2[\"liste_adresse\"]\n",
    "    )\n",
    "    \n",
    "    df_inter2[\"is_entrepreneur_individuel\"] = df_inter2.apply(lambda x: True if x.nature_juridique_unite_legale in ['1', '10', '1000'] else False, axis=1) # entrepreneur individuel\n",
    "    df_inter2[\"coordonnees\"] = df_inter2.apply(lambda x: None if ((x.latitude!=x.latitude) or (x.longitude!=x.longitude)) else (x.latitude + \",\" + x.longitude) , axis=1)\n",
    "    df_inter2['nombre_etablissements_ouverts'] = df_inter2['nombre_etablissements_ouverts'].replace({np.nan: 0})\n",
    "    df_inter2['nombre_etablissements'] = df_inter2['nombre_etablissements'].replace({np.nan: 1})\n",
    "    df_inter2['nombre_etablissements'] = df_inter2['nombre_etablissements'].astype(int)\n",
    "    df_inter2['nombre_etablissements_ouverts'] = df_inter2['nombre_etablissements_ouverts'].astype(int)\n",
    "    df_inter2['departement'] = df_inter2.apply(lambda x: str(x.commune)[:3] if str(x.commune)[:2]==\"97\" else str(x.commune)[:2], axis=1)\n",
    "    df_inter2.drop(columns='is_siege', axis=1, inplace=True)\n",
    "    df_inter2['adresse_etablissement'] = df_inter2.apply(lambda x: adresse_complete(x), axis=1)\n",
    "    df_inter2['is_entrepreneur_individuel'] = df_inter2['is_entrepreneur_individuel'].map({True: 'true', False: 'false'}) # Elastic only takes 'true' and 'false' as bool\n",
    "    df_inter2 = df_inter2.rename(\n",
    "        columns={\n",
    "            \"activite_principale\": \"activite_principale_siege\",\n",
    "            \"date_creation\": \"date_creation_siege\",\n",
    "            \"date_debut_activite\": \"date_debut_activite_siege\",\n",
    "            \"etat_administratif_etablissement\": \"etat_administratif_siege\",\n",
    "            \"siret\": \"siret_siege\",\n",
    "            \"tranche_effectif_salarie\": \"tranche_effectif_salarie_siege\",\n",
    "        }\n",
    "    )\n",
    "    '''\n",
    "    df_inter.to_csv(\n",
    "        OUTPUT_DATA_FOLDER + \"siret_\" + geo_file.replace(DATA_DIR + \"geo_siret_\", \"\"),\n",
    "        index=False,\n",
    "    )\n",
    "    '''\n",
    "    df_inter2.to_csv(\n",
    "        OUTPUT_DATA_FOLDER\n",
    "        + ELASTIC_INDEX\n",
    "        + \"_\"\n",
    "        + geo_file.replace(DATA_DIR + \"geo_siret_\", \"\"),\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter2.columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19ece5f74f8baf7d074e990d308e7c75b7ac8b98c7c6e76faedd0c3526d006f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
